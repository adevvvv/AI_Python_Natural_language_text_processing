{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "3c0d5394-52e6-4547-ae83-af02585a24b0",
      "metadata": {},
      "source": [
        "### Обработка текстов на естественном языке"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4fac8a9-72d1-4511-8903-d6e3c51d71b4",
      "metadata": {},
      "source": [
        "## 1. Лингвистический анализ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2a810744-c678-4255-99cc-b1e9b338d4f2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import natasha\n",
        "import pymorphy2\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "00e4f635-bdb5-491c-94d0-21232f5ac054",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>tags</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://lenta.ru/news/1999/10/04/tv/</td>\n",
              "      <td>Телеканалы станут вещать по единому тарифу</td>\n",
              "      <td>С 1 января 2000 года все телеканалы будут опла...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>Все</td>\n",
              "      <td>1999/10/04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://lenta.ru/news/1999/10/04/volkswagen/</td>\n",
              "      <td>Volkswagen выкупает остатки акций \"Шкоды\"</td>\n",
              "      <td>Германский автопромышленный концерн Volkswagen...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>Все</td>\n",
              "      <td>1999/10/04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lenta.ru/news/1999/10/04/tumen/</td>\n",
              "      <td>Прибыль Тюменнефтегаза возросла в 10 раз</td>\n",
              "      <td>Нераспределенная прибыль ОАО \"Тюменнефтегаз\", ...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>Все</td>\n",
              "      <td>1999/10/04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://lenta.ru/news/1999/10/05/sprint/</td>\n",
              "      <td>Крупнейшее в истории слияние компаний происход...</td>\n",
              "      <td>Две крупнейших телекоммуникационных компании С...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>Все</td>\n",
              "      <td>1999/10/05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://lenta.ru/news/1999/10/05/volga/</td>\n",
              "      <td>ГАЗ получил четверть обещанного кредита</td>\n",
              "      <td>ОАО \"ГАЗ\" и Нижегородский банк Сбербанка Росси...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>Все</td>\n",
              "      <td>1999/10/05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197733</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/oleinik/</td>\n",
              "      <td>Российский боец UFC включен в Книгу рекордов Г...</td>\n",
              "      <td>Российский боец смешанного стиля (MMA) Алексей...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>Бокс и ММА</td>\n",
              "      <td>2018/12/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197734</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/frank_myr/</td>\n",
              "      <td>Бывший чемпион UFC не выдержал кровопролития и...</td>\n",
              "      <td>Американский боец смешанного стиля (MMA) Фрэн...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>Бокс и ММА</td>\n",
              "      <td>2018/12/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197735</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/mebel/</td>\n",
              "      <td>Моуринью сравнил футболистов с мебелью</td>\n",
              "      <td>Главный тренер «Манчестер Юнайтед» Жозе Моурин...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>Футбол</td>\n",
              "      <td>2018/12/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197736</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/putinrap/</td>\n",
              "      <td>Путин предостерег от запретов рэп-концертов</td>\n",
              "      <td>Президент России Владимир Путин, выступая на з...</td>\n",
              "      <td>Культура</td>\n",
              "      <td>Музыка</td>\n",
              "      <td>2018/12/15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197737</th>\n",
              "      <td>https://lenta.ru/news/2018/12/15/gizin/</td>\n",
              "      <td>Падение горнолыжника на полной скорости попало...</td>\n",
              "      <td>Швейцарский горнолыжник Марк Гизин неудачно пр...</td>\n",
              "      <td>Спорт</td>\n",
              "      <td>Зимние виды</td>\n",
              "      <td>2018/12/15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>197738 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  \\\n",
              "0               https://lenta.ru/news/1999/10/04/tv/   \n",
              "1       https://lenta.ru/news/1999/10/04/volkswagen/   \n",
              "2            https://lenta.ru/news/1999/10/04/tumen/   \n",
              "3           https://lenta.ru/news/1999/10/05/sprint/   \n",
              "4            https://lenta.ru/news/1999/10/05/volga/   \n",
              "...                                              ...   \n",
              "197733     https://lenta.ru/news/2018/12/15/oleinik/   \n",
              "197734   https://lenta.ru/news/2018/12/15/frank_myr/   \n",
              "197735       https://lenta.ru/news/2018/12/15/mebel/   \n",
              "197736    https://lenta.ru/news/2018/12/15/putinrap/   \n",
              "197737       https://lenta.ru/news/2018/12/15/gizin/   \n",
              "\n",
              "                                                    title  \\\n",
              "0              Телеканалы станут вещать по единому тарифу   \n",
              "1               Volkswagen выкупает остатки акций \"Шкоды\"   \n",
              "2                Прибыль Тюменнефтегаза возросла в 10 раз   \n",
              "3       Крупнейшее в истории слияние компаний происход...   \n",
              "4                 ГАЗ получил четверть обещанного кредита   \n",
              "...                                                   ...   \n",
              "197733  Российский боец UFC включен в Книгу рекордов Г...   \n",
              "197734  Бывший чемпион UFC не выдержал кровопролития и...   \n",
              "197735             Моуринью сравнил футболистов с мебелью   \n",
              "197736        Путин предостерег от запретов рэп-концертов   \n",
              "197737  Падение горнолыжника на полной скорости попало...   \n",
              "\n",
              "                                                     text      topic  \\\n",
              "0       С 1 января 2000 года все телеканалы будут опла...  Экономика   \n",
              "1       Германский автопромышленный концерн Volkswagen...  Экономика   \n",
              "2       Нераспределенная прибыль ОАО \"Тюменнефтегаз\", ...  Экономика   \n",
              "3       Две крупнейших телекоммуникационных компании С...  Экономика   \n",
              "4       ОАО \"ГАЗ\" и Нижегородский банк Сбербанка Росси...  Экономика   \n",
              "...                                                   ...        ...   \n",
              "197733  Российский боец смешанного стиля (MMA) Алексей...      Спорт   \n",
              "197734   Американский боец смешанного стиля (MMA) Фрэн...      Спорт   \n",
              "197735  Главный тренер «Манчестер Юнайтед» Жозе Моурин...      Спорт   \n",
              "197736  Президент России Владимир Путин, выступая на з...   Культура   \n",
              "197737  Швейцарский горнолыжник Марк Гизин неудачно пр...      Спорт   \n",
              "\n",
              "               tags        date  \n",
              "0               Все  1999/10/04  \n",
              "1               Все  1999/10/04  \n",
              "2               Все  1999/10/04  \n",
              "3               Все  1999/10/05  \n",
              "4               Все  1999/10/05  \n",
              "...             ...         ...  \n",
              "197733   Бокс и ММА  2018/12/15  \n",
              "197734   Бокс и ММА  2018/12/15  \n",
              "197735       Футбол  2018/12/15  \n",
              "197736       Музыка  2018/12/15  \n",
              "197737  Зимние виды  2018/12/15  \n",
              "\n",
              "[197738 rows x 6 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/lenta/lenta-subset.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ddeecd-b100-4926-93cd-bedfac2c52c2",
      "metadata": {},
      "source": [
        "Токенизация (графематический анализ)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "743d8edf-970e-4c66-ad77-0643bdf0d8cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = natasha.Doc(df.iloc[3].text)\n",
        "segmenter = natasha.Segmenter()\n",
        "doc.segment(segmenter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6b299475-4a90-4d68-8a17-c676757f9fe1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Doc(text='Две крупнейших телекоммуникационных компании США ..., tokens=[...], sents=[...])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e3fda63d-ab0a-4247-ae97-bbaaec307abb",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[DocSent(stop=83, text='Две крупнейших телекоммуникационных компании США ..., tokens=[...]),\n",
              " DocSent(start=84, stop=315, text='По сообщению агентства Reuters корпорация Sprint ..., tokens=[...]),\n",
              " DocSent(start=316, stop=450, text='Сумма намечающейся сделки должна составить 115 ми..., tokens=[...]),\n",
              " DocSent(start=451, stop=682, text='Ожидается, что \"итоговая\" корпорация будет контро..., tokens=[...]),\n",
              " DocSent(start=683, stop=750, text='Эта сделка продолжает ряд суперслияний в телефонн..., tokens=[...]),\n",
              " DocSent(start=751, stop=854, text='Предыдущим являлась покупка руководителем WorldCo..., tokens=[...]),\n",
              " DocSent(start=855, stop=952, text='На нью-йоркской бирже акции Sprint незамедлительн..., tokens=[...]),\n",
              " DocSent(start=953, stop=1041, text='В структуре акционерного капитала Sprint участвую..., tokens=[...]),\n",
              " DocSent(start=1042, stop=1116, text='Пока неизвестно судьба их пакетов акций, каждый и..., tokens=[...])]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d04075ce-a6c1-4579-9b41-a289df7d9a50",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[DocToken(stop=3, text='Две'),\n",
              " DocToken(start=4, stop=14, text='крупнейших'),\n",
              " DocToken(start=15, stop=35, text='телекоммуникационных'),\n",
              " DocToken(start=36, stop=44, text='компании'),\n",
              " DocToken(start=45, stop=48, text='США')]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "76103d4d-1dff-448a-87bf-d132c50cb94f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[DocToken(stop=3, text='Две'),\n",
              " DocToken(start=4, stop=14, text='крупнейших'),\n",
              " DocToken(start=15, stop=35, text='телекоммуникационных'),\n",
              " DocToken(start=36, stop=44, text='компании'),\n",
              " DocToken(start=45, stop=48, text='США'),\n",
              " DocToken(start=49, stop=57, text='достигли'),\n",
              " DocToken(start=58, stop=72, text='договоренности'),\n",
              " DocToken(start=73, stop=74, text='о'),\n",
              " DocToken(start=75, stop=82, text='слиянии'),\n",
              " DocToken(start=82, stop=83, text='.')]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc.sents[0].tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "68063cb0-f612-4edb-ad87-c05d409a6498",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Две',\n",
              " 'крупнейших',\n",
              " 'телекоммуникационных',\n",
              " 'компании',\n",
              " 'США',\n",
              " 'достигли',\n",
              " 'договоренности',\n",
              " 'о',\n",
              " 'слиянии',\n",
              " '.']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[x.text for x in doc.sents[0].tokens]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dcd3ef8-afba-452f-a0f8-62e89656ce91",
      "metadata": {},
      "source": [
        "#### Синтаксический разбор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d624371f-48b9-46e9-a157-01279f8078a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  ┌────► Две                  nummod:gov\n",
            "  │ ┌──► крупнейших           amod\n",
            "  │ │ ┌► телекоммуникационных amod\n",
            "  └─└─└─ компании             nsubj\n",
            "  │ └──► США                  nmod\n",
            "┌─└───┌─ достигли             \n",
            "│   ┌─└► договоренности       obj\n",
            "│   │ ┌► о                    case\n",
            "│   └►└─ слиянии              nmod\n",
            "└──────► .                    punct\n"
          ]
        }
      ],
      "source": [
        "emb = natasha.NewsEmbedding()\n",
        "syntax_parser = natasha.NewsSyntaxParser(emb)\n",
        "doc.parse_syntax(syntax_parser)\n",
        "doc.sents[0].syntax.print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a43feffe-c83f-4fe6-b06d-4449e007c272",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('компании', 'достигли')\n",
            "('корпорация', 'приняла')\n",
            "('Сумма', 'должна')\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "list index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m subject[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext, aux[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m root\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m aux \u001b[38;5;28;01melse\u001b[39;00m root\u001b[38;5;241m.\u001b[39mtext  \n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sent \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mextract_basis\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m)\u001b[49m)\n",
            "Cell \u001b[1;32mIn[10], line 9\u001b[0m, in \u001b[0;36mextract_basis\u001b[1;34m(syntactic_tree)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Найти подлежащее\u001b[39;00m\n\u001b[0;32m      8\u001b[0m subject \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m syntactic_tree\u001b[38;5;241m.\u001b[39mtokens \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mhead_id \u001b[38;5;241m==\u001b[39m root\u001b[38;5;241m.\u001b[39mid \u001b[38;5;129;01mand\u001b[39;00m (x\u001b[38;5;241m.\u001b[39mrel \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsubj\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x\u001b[38;5;241m.\u001b[39mrel\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsubj:pass\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msubject\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtext, aux[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m root\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mif\u001b[39;00m aux \u001b[38;5;28;01melse\u001b[39;00m root\u001b[38;5;241m.\u001b[39mtext\n",
            "\u001b[1;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "def extract_basis(syntactic_tree):\n",
        "    # id2token = {x.id: x for x in syntactic_tree.tokens}\n",
        "    # Найти главное слово - сказуемое\n",
        "    root = [x for x in syntactic_tree.tokens if x.rel == 'root'][0]\n",
        "    # Проверить, есть ли у него какие-то модификаторы (aux)\n",
        "    aux = [x for x in syntactic_tree.tokens if x.head_id == root.id and (x.rel=='aux' or x.rel=='aux:pass')]\n",
        "    # Найти подлежащее\n",
        "    subject = [x for x in syntactic_tree.tokens if x.head_id == root.id and (x.rel == 'nsubj' or x.rel=='nsubj:pass')]\n",
        "    return subject[0].text, aux[0].text + ' ' + root.text if aux else root.text  \n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(extract_basis(sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9d072fe-75a9-4119-92fe-488488f1864e",
      "metadata": {},
      "source": [
        "##### 1.1.  Используя синтаксический анализатор в составе библиотеки natasha, доработать процедуру выделения основ предложений, чтобы она работала и со сложными предложениями (выделяла все основы сложносочиненных и сложноподчиненных предложений). \n",
        "- Пример предложения: Две крупнейших телекоммуникационных компании США достигли договоренности о слиянии"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a6c71761-5239-4500-b9a6-c9cff3bf1a52",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('компании', ' достигли')\n",
            "('корпорация', ' приняла')\n",
            "('Сумма', ' должна')\n",
            "('сделка', ' продолжает')\n",
            "('покупка', ' являлась')\n",
            "('акции', ' поднялись')\n",
            "('BellSouth', ' потеряла')\n",
            "('Deutsche', ' участвуют')\n",
            "('судьба', ' неизвестно')\n"
          ]
        }
      ],
      "source": [
        "def extract_complex(syntactic_tree):\n",
        "    complex = []\n",
        "    roots = [x for x in syntactic_tree.tokens if x.rel == 'root']  \n",
        "    for root in roots:\n",
        "        subjects = [x for x in syntactic_tree.tokens if x.head_id == root.id and (x.rel == 'nsubj' or x.rel == 'nsubj:pass')]\n",
        "        if subjects:\n",
        "            subject = subjects[0]\n",
        "            aids = [x for x in syntactic_tree.tokens if x.head_id == root.id and (x.rel == 'aux' or x.rel == 'aux:pass')]\n",
        "            aux_text = ' '.join([aux.text for aux in aids]) if aids else ''\n",
        "            complex.append((subject.text, aux_text + ' ' + root.text))\n",
        "            for conj_root in [x for x in syntactic_tree.tokens if x.head_id == root.id and x.rel == 'conj']:\n",
        "                aids_conj = [x for x in syntactic_tree.tokens if x.head_id == conj_root.id and (x.rel == 'aux' or x.rel == 'aux:pass')]\n",
        "                aux_text_conj = ' '.join([aux.text for aux in aids_conj]) if aids_conj else ''\n",
        "                subjects_conj = [x for x in syntactic_tree.tokens if x.head_id == conj_root.id and (x.rel == 'nsubj' or x.rel == 'nsubj:pass')]\n",
        "                if subjects_conj:\n",
        "                    subject_conj = subjects_conj[0]\n",
        "                    complex.append((subject_conj.text, aux_text_conj + ' ' + conj_root.text))\n",
        "        return complex if complex else None\n",
        "\n",
        "for sent in doc.sents:\n",
        "    complex = extract_complex(sent.syntax)\n",
        "    if complex:\n",
        "        for b in complex:\n",
        "            print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b299331-734f-4b13-b71a-8919be70774e",
      "metadata": {},
      "source": [
        "##### 1.2. Разработать функцию, которая бы выделяла из текста упоминания персоналий. Сопоставить множества персоналий, наиболее часто упоминаемых в новостях Экономики за 2000 и 2015 годы.\n",
        "##### 1.3. Разработать функцию, которая бы выделяла множество действий, совершенных заданной персоналией («Х поручил то-то, Х предложил то-то, что-то было предложено Х»).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "a93bf849-cd7f-43bd-8383-7f8cbc9315a1",
      "metadata": {},
      "outputs": [],
      "source": [
        "from natasha import NamesExtractor, MorphVocab\n",
        "from collections import defaultdict\n",
        "from datetime import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "c0a29625-6893-47fa-a1f2-17c85fa45f82",
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_persons(text):\n",
        "    morph_dict = MorphVocab()\n",
        "    extractor = NamesExtractor(morph_dict)\n",
        "    matches = extractor(text)\n",
        "    return [match.fact.first for match in matches]\n",
        "\n",
        "def extract_actions_persons(text, person_name):\n",
        "    doc = natasha.Doc(text)\n",
        "    doc.segment(segmenter)\n",
        "    doc.parse_syntax(syntax_parser)\n",
        "    actions = set()\n",
        "    for sent in doc.sents:\n",
        "        main_word = next((token.text.lower() for token in sent.tokens if token.rel == 'nsubj'), None)\n",
        "\n",
        "        if main_word and main_word == person_name.lower():\n",
        "            root_tokens = [token.text for token in sent.tokens if token.rel == 'root']\n",
        "            noun_tokens = [token.text for token in sent.tokens if (token.rel == 'obj' or token.rel == 'obj:pass')]\n",
        "\n",
        "            root = root_tokens[0] if root_tokens else ''\n",
        "            noun = ' '.join(noun_tokens) if noun_tokens else ''\n",
        "\n",
        "            action = f\"{main_word} {root} {noun}\".strip()\n",
        "            actions.add(action)\n",
        "\n",
        "    return actions\n",
        "\n",
        "def persons_and_actions(year, n):\n",
        "    df['year'] = pd.to_datetime(df['date']).dt.year\n",
        "    data_year = df[(df['year'] == year) & (df['topic'] == 'Экономика')]\n",
        "    data_year['found_persons'] = None \n",
        "\n",
        "    for i, row in data_year.iterrows():\n",
        "        persons_list = extract_persons(row['text'])\n",
        "        if persons_list:\n",
        "            data_year.at[i, 'found_persons'] = persons_list[0]\n",
        "    data_person = pd.DataFrame(data_year['found_persons'][data_year['found_persons'].notna()].tolist())\n",
        "    person = pd.concat([data_person], ignore_index=True).drop_duplicates()\n",
        "    print(\"Персонали: \", person)\n",
        "    if n == 1:\n",
        "        for _, row in person[:1].iterrows():\n",
        "             person_name = row[0]\n",
        "             print(person_name)\n",
        "             for _, news_row in data_year[:50].iterrows():\n",
        "                 text = news_row['text']\n",
        "                 actions = extract_actions_persons(text, person_name)\n",
        "                 if actions:\n",
        "                     print(\"Действие персоналя:\")\n",
        "                     print('\\n'.join(actions))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa700d93-2077-4315-8d54-4879019937ee",
      "metadata": {},
      "source": [
        "1.2. Персонали в новостях Экономики за 2000 год:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4edea6d9-9ff4-47c4-a7dc-3f0eb5d6fba1",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\AppData\\Local\\Temp\\ipykernel_9568\\3346425889.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_year['found_persons'] = None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Персонали:                  0\n",
            "0        Владимир\n",
            "5            Билл\n",
            "7             Рем\n",
            "12          Борис\n",
            "13        Евгений\n",
            "16             из\n",
            "18         Келера\n",
            "19        Герхард\n",
            "21          марта\n",
            "26         семена\n",
            "28         Леонид\n",
            "29          света\n",
            "34        Жераром\n",
            "35        Дмитрий\n",
            "36     Владимиром\n",
            "40          Ливии\n",
            "43            мая\n",
            "46        Михаила\n",
            "47        Алексей\n",
            "48           дали\n",
            "51         Михаил\n",
            "57         алмазы\n",
            "58              Ю\n",
            "61         Джордж\n",
            "63        Дональд\n",
            "64      Александр\n",
            "65       Бурхарда\n",
            "69       Анатолий\n",
            "71         Виктор\n",
            "78             Из\n",
            "80           овет\n",
            "81        августа\n",
            "88          Ямало\n",
            "91     Русатоммет\n",
            "108           АВВ\n",
            "113           Али\n",
            "117         марки\n",
            "120  Европаламент\n"
          ]
        }
      ],
      "source": [
        "persons_and_actions(2000, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9077d177-4b91-4cdf-9126-62deb1cbbd95",
      "metadata": {},
      "source": [
        "1.2. Персонали в новостях Экономики за 2015 год:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c9716c7d-5a91-43bb-bf0c-10444dda91f8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\AppData\\Local\\Temp\\ipykernel_9568\\3346425889.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_year['found_persons'] = None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Персонали:               0\n",
            "0           из\n",
            "1         ФИЭО\n",
            "2        ОСАГО\n",
            "5      Дмитрий\n",
            "6     Владимир\n",
            "7         доля\n",
            "10       РусАл\n",
            "15     Аркадий\n",
            "16       Петра\n",
            "17       Дания\n",
            "21          Из\n",
            "22   Нурсултан\n",
            "25     Алексей\n",
            "27        Петр\n",
            "28        свет\n",
            "31       марта\n",
            "33        Доля\n",
            "41        веры\n",
            "46   Владимира\n",
            "47      Герман\n",
            "48        Джим\n",
            "55      Ксения\n",
            "58       Афины\n",
            "61       Альфа\n",
            "66      финанс\n",
            "72      Барака\n",
            "76         том\n",
            "78      Интеко\n",
            "80       Борис\n",
            "81     Роструд\n",
            "87   Александр\n",
            "89       Белла\n",
            "90      Михаил\n",
            "91         май\n",
            "92    Тинькофф\n",
            "96       БРИКС\n",
            "99       Ольга\n",
            "105       Афин\n",
            "106     Пуэрто\n",
            "107   Бинбанка\n",
            "108        Том\n",
            "118      Наиль\n",
            "122  Екатерина\n",
            "126    Автодор\n",
            "132    Евгений\n",
            "133    августа\n",
            "136    Николас\n",
            "139      Игорь\n",
            "140     Нирадж\n",
            "146     рудами\n",
            "148      Барак\n",
            "149      марка\n",
            "155       Слим\n",
            "156       Кубе\n",
            "160     Ингвар\n",
            "167    Нуриэль\n",
            "189    Георгий\n"
          ]
        }
      ],
      "source": [
        "persons_and_actions(2015, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96e6daed-f41a-4d74-ab7b-373d5af439cd",
      "metadata": {},
      "source": [
        "1.3. Выберем например Владимира и выведем соверешенные им действия:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e94f66be-979f-4ef5-a5f7-8032cccc9512",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\AppData\\Local\\Temp\\ipykernel_9568\\3346425889.py:30: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data_year['found_persons'] = None\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Персонали:                  0\n",
            "0        Владимир\n",
            "5            Билл\n",
            "7             Рем\n",
            "12          Борис\n",
            "13        Евгений\n",
            "16             из\n",
            "18         Келера\n",
            "19        Герхард\n",
            "21          марта\n",
            "26         семена\n",
            "28         Леонид\n",
            "29          света\n",
            "34        Жераром\n",
            "35        Дмитрий\n",
            "36     Владимиром\n",
            "40          Ливии\n",
            "43            мая\n",
            "46        Михаила\n",
            "47        Алексей\n",
            "48           дали\n",
            "51         Михаил\n",
            "57         алмазы\n",
            "58              Ю\n",
            "61         Джордж\n",
            "63        Дональд\n",
            "64      Александр\n",
            "65       Бурхарда\n",
            "69       Анатолий\n",
            "71         Виктор\n",
            "78             Из\n",
            "80           овет\n",
            "81        августа\n",
            "88          Ямало\n",
            "91     Русатоммет\n",
            "108           АВВ\n",
            "113           Али\n",
            "117         марки\n",
            "120  Европаламент\n",
            "Владимир\n",
            "Действие персоналя:\n",
            "владимир подписал постановление\n",
            "Действие персоналя:\n",
            "владимир отметил ряд\n"
          ]
        }
      ],
      "source": [
        "persons_and_actions(2000, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "776e5b79-5b20-4803-9c7b-4e74bc5b23d5",
      "metadata": {},
      "source": [
        "### 2. Векторная модель документа:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c1ae110-eb79-4a45-a6d9-1555e5e895b1",
      "metadata": {},
      "source": [
        "2.1. Провести анализ того, как качество тематической классификации новости без лемматизации зависит от размера обучающего множества (см. кривые обучения в зависимости от размера обучающего множества). Сопоставить с качеством классификации модели с лемматизацией.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "199f5065-6bd7-4e1c-bfd0-f5373b49ef02",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8c5aad5f-147b-4e09-8a2d-c8b4e2444fba",
      "metadata": {},
      "outputs": [],
      "source": [
        "df.groupby(by='topic').count()\n",
        "economy = df\n",
        "economy['target'] = (economy['topic'] == 'Экономика').astype(np.int8)\n",
        "economy = economy[['text', 'target']]\n",
        "df.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8ec1a10e-f51b-4147-97d5-2bf873d5a6ad",
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorizer = CountVectorizer(\n",
        "    max_df=0.7,    # Делать признаками слова, которые содержатся в не более, чем заданной доле документов\n",
        "    min_df=10      # Делать признаки из слов, которые содержатся, по крайней мере, в заданном количестве документов\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e585a1b3-2536-4ba4-a2ea-433022a273c6",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\miniconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_economy = vectorizer.fit_transform(economy.text)\n",
        "X_economy_train, X_economy_test, y_economy_train, y_economy_test = train_test_split(X_economy, economy.target, test_size=0.2, random_state=42, stratify=economy.target)\n",
        "lm_economy = LogisticRegression()\n",
        "lm_economy.fit(X_economy_train, y_economy_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "24548b21-c985-4a78-9b34-6de49d0a9006",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9942241149853607\n",
            "ROC_AUC: 0.999347440144986\n"
          ]
        }
      ],
      "source": [
        "print('Accuracy:', accuracy_score(y_economy_test, lm_economy.predict(X_economy_test)))\n",
        "print('ROC_AUC:', roc_auc_score(y_economy_test, lm_economy.predict_proba(X_economy_test)[:, 1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a3f3ca-8235-419e-a9fb-909614b39ba2",
      "metadata": {},
      "source": [
        "#### 3. Вложения (эмбеддинги) слов:\n",
        "3.1. Загрузить модель эмбеддингов слов, обученную на художественной литературе (см.\n",
        "https://github.com/natasha/navec). Для выбранного набора слов сопоставить схожие слова\n",
        "(расположенные рядом в пространстве вложения) и рассуждение по аналогии. Есть ли\n",
        "разница с моделью вложений, обученной на новостных сообщениях?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "5153ac7b-df3c-4329-9840-2b9828fce679",
      "metadata": {},
      "outputs": [],
      "source": [
        "import heapq\n",
        "\n",
        "def euclidean_distance(x, y):\n",
        "    return np.linalg.norm(x - y)\n",
        "\n",
        "def cosine_similarity(x, y):\n",
        "    return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n",
        "\n",
        "def find_closest_words(emb, words, k=5, similarity=cosine_similarity):\n",
        "    \"\"\"Поиск k ближайших слов для каждого слова из списка.\"\"\"\n",
        "    result = {}\n",
        "    for word in words:\n",
        "        word_vector = emb[word]\n",
        "        word_distances = [(-similarity(emb[other_word], word_vector), other_word) for other_word in emb.vocab.words]\n",
        "        closest_words = heapq.nsmallest(k, word_distances)\n",
        "        result[word] = [w for (_, w) in closest_words]\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "11263c06-ca02-4f83-a118-410d3e6e528e",
      "metadata": {},
      "outputs": [],
      "source": [
        "example_words = ['важное', 'событие']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "9e010bec-9986-4ff1-9376-9853cdb5303a",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\AppData\\Local\\Temp\\ipykernel_9568\\299431391.py:7: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  return np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ближайшие слова для'важное': ['важное', 'ключевое', 'значение', 'важнейшее', 'самое']\n",
            "Ближайшие слова для'событие': ['событие', 'знаковое', 'событием', 'знаменательное', 'важное']\n"
          ]
        }
      ],
      "source": [
        "closest_words_dict = find_closest_words(emb, example_words, k=5, similarity=cosine_similarity)\n",
        "for word, closest_words in closest_words_dict.items():\n",
        "    print(f\"Ближайшие слова для'{word}': {closest_words}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "f59ed95c-7881-406a-99a2-c4814b752c73",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from slovnet.model.emb import NavecEmbedding\n",
        "from navec import Navec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "874f51f1-2024-483d-b388-a11c7126e4da",
      "metadata": {},
      "outputs": [],
      "source": [
        "navec = Navec.load(r'C:\\Users\\adevv\\Downloads\\navec.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "d1a16cce-9a28-4e73-b8df-125e85e8fdb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\miniconda3\\Lib\\site-packages\\slovnet\\model\\emb.py:46: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:212.)\n",
            "  torch.from_numpy(navec.pq.indexes),\n"
          ]
        }
      ],
      "source": [
        "emb_layer = NavecEmbedding(emb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ca686820-4769-4d75-b823-89cc6dd17c03",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 300])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input = torch.tensor([1, 2, 3])\n",
        "emb_layer(input).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "7e688052-e853-4fbc-97e5-28bf172f6d27",
      "metadata": {},
      "outputs": [],
      "source": [
        "def similar_words(word, navec, topn=5):\n",
        "    word_vec = navec[word]\n",
        "    sw = []\n",
        "\n",
        "    for other_word in navec.vocab.words:\n",
        "        if other_word != word:\n",
        "            other_vec = navec[other_word]\n",
        "            similarity = np.dot(word_vec, other_vec) / (np.linalg.norm(word_vec) * np.linalg.norm(other_vec))\n",
        "            sw.append((other_word, similarity))\n",
        "\n",
        "    sw = sorted(sw, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    tsw = sw[:topn]\n",
        "    return tsw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "cae28c45-048d-4c53-9bc3-79f27c0d6853",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\adevv\\AppData\\Local\\Temp\\ipykernel_9568\\2106215094.py:8: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  similarity = np.dot(word_vec, other_vec) / (np.linalg.norm(word_vec) * np.linalg.norm(other_vec))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Ближайшие слова для 'важное': интересное, самое, серьезное, значение, другое, \n",
            "\n",
            "Ближайшие слова для 'событие': происшествие, знаменательное, событием, события, случившееся, \n"
          ]
        }
      ],
      "source": [
        "for search_word in example_words:\n",
        "    sw = similar_words(search_word, navec, topn=5)\n",
        "    print(f\"\\nБлижайшие слова для '{search_word}':\", end=' ')\n",
        "    for word, similarity in sw:\n",
        "        print(f\"{word}\", end=', ')\n",
        "    print() "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09ee1aff-4fbb-4b49-8e20-841e2901a368",
      "metadata": {},
      "source": [
        "#### 4. Нейросетевая обработка текстов:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a893ff8-26f0-49a8-b220-7dd2d374966c",
      "metadata": {},
      "source": [
        "4.1. Тематический классификатор новостей на основе LSTM демонстрирует очень\n",
        "высокое качество классификации буквально с первой эпохи обучения. Но является ли это\n",
        "«заслугой» LSTM или качественного набора эмбеддингов? Реализуйте простейший\n",
        "классификатор сообщений, в котором на вход полносвязному слою передается просто\n",
        "среднее арифметическое эмбеддингов слов. Сопоставьте качество классификации с\n",
        "моделью на основе LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e8d3c4dd-48e8-41d0-9e07-d88efc0c8add",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch \n",
        "from natasha import Segmenter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c78d21cc-4993-4dd8-847b-3af12d7d6168",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmartTokenizer:\n",
        "    \"\"\"Класс для выделения токенов.\n",
        "    \n",
        "    Использует библиотеку natasha для токенизации и лемматизации,\n",
        "    оставляет только существительные и глаголы.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        emb = natasha.NewsEmbedding()\n",
        "        self.segmenter = natasha.Segmenter()\n",
        "        self.morph_tagger = natasha.NewsMorphTagger(emb)\n",
        "        self.morph_vocab = natasha.MorphVocab()\n",
        "    \n",
        "    def __call__(self, text):\n",
        "        doc = natasha.Doc(text)\n",
        "        doc.segment(self.segmenter)\n",
        "        doc.tag_morph(self.morph_tagger)\n",
        "        tokens = []\n",
        "        for token in doc.tokens:\n",
        "            if token.pos in ['NOUN', 'VERB']:\n",
        "                token.lemmatize(morph_vocab)\n",
        "                tokens.append(token.lemma)\n",
        "        return tokens\n",
        "\n",
        "improved_vectorizer = CountVectorizer(\n",
        "    tokenizer=SmartTokenizer(),\n",
        "    token_pattern=None,\n",
        "    max_df=0.7,    # Делать признаками слова, которые содержатся в не более, чем заданной доле документов\n",
        "    min_df=10      # Делать признаки из слов, которые содержатся, по крайней мере, в заданном количестве документов\n",
        ")\n",
        "\n",
        "morph_vocab = natasha.MorphVocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "63776713-28ff-464e-93f8-e273227104ae",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_test = economy[:1000].copy()\n",
        "df_train = economy[1000:].copy().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8acc5799-15d4-40ca-a9ed-645a25e5049b",
      "metadata": {},
      "outputs": [],
      "source": [
        "emb = natasha.NewsEmbedding()\n",
        "segmenter = Segmenter()\n",
        "\n",
        "def text_to_ids(emb, text: str, length: int) -> torch.tensor:\n",
        "    \"\"\"Преобразование строки в тензор с номерами токенов.\"\"\"\n",
        "    # Пунктуационные токены (их кодировать не будем)\n",
        "    punct = [',', '.', ';', ':', '-', '...', '!', '?']\n",
        "    # Проведем токенизацию текста\n",
        "    d = natasha.Doc(text)\n",
        "    d.segment(segmenter)\n",
        "    # Для каждого токена, который найдется в словаре эмбеддингов подставим\n",
        "    # его номер, для прочих подставим номер <unk>\n",
        "    tmp = torch.tensor([emb.vocab.get(x.text.lower(), emb.vocab.unk_id)\n",
        "                       for x in d.tokens\n",
        "                       if x.text not in punct][:length])\n",
        "    # Дополним последовательность (спереди) токенами <pad>\n",
        "    return torch.nn.functional.pad(tmp, (length - len(tmp), 0), \"constant\", emb.vocab.pad_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "261f5576-e1fa-4fba-8401-01b1ac0c656a",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.stack([text_to_ids(emb, x, 50) for x in economy.text], 0)\n",
        "y = torch.unsqueeze(torch.tensor(economy.target, dtype=torch.float32), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "084eaf67-b555-474e-aff3-751e6a2b4be9",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = torch.stack([text_to_ids(emb, x, 50) for x in df_test.text], 0)\n",
        "Y_test = torch.unsqueeze(torch.tensor(df_test.target, dtype=torch.float32), 1)\n",
        "data_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y), batch_size=8)\n",
        "test_data_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, Y_test), batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "5ba83194-113f-4fef-93af-c69c462314d9",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SimpleLSTMClassifier(nn.Module):\n",
        "    \"\"\"Простой классификатор текста.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Специальная обёртка, позволяющая использовать\n",
        "        # эмбеддинги natasha как слой сети PyTorch\n",
        "        self.embedding = NavecEmbedding(emb)\n",
        "        # LSTM-слой.\n",
        "        # Обратите внимание на batch_first=True !\n",
        "        # По умолчанию этот параметр равен False и первая размерность\n",
        "        # интерпретируется как длина последовательности, а не батча - \n",
        "        # если это не поменять, то сеть будет учиться на \"каше\" из данных\n",
        "        self.lstm = nn.LSTM(300,   # размерность элемента последовательности (эмбеддинга)\n",
        "                            30,    # выходная размерность\n",
        "                            batch_first=True)\n",
        "        self.fc = nn.Linear(30, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        # Используйте размерность 1, чтобы выбрать последний временной шаг\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "39143d94-6de1-4ed2-b3be-b614f279d21d",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SimpleLSTMClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "eaf9e1b1-f429-4545-8dcf-ac3778bbc956",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss=0.6931. Test accuracy 0.9000 ROC_AUC 0.9923\n",
            "Epoch 1: train loss=0.6931. Test accuracy 0.9030 ROC_AUC 0.9989\n",
            "Epoch 2: train loss=0.6931. Test accuracy 0.9080 ROC_AUC 0.9957\n",
            "Epoch 3: train loss=0.6931. Test accuracy 0.9060 ROC_AUC 0.9960\n",
            "Epoch 4: train loss=0.6931. Test accuracy 0.9260 ROC_AUC 0.9980\n"
          ]
        }
      ],
      "source": [
        "criterion = torch.nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    for X, y in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(X)\n",
        "        loss = criterion(pred_logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            pred_logits = model(X)\n",
        "            preds.append(torch.sigmoid(pred_logits))\n",
        "    preds = torch.cat(preds)\n",
        "    print(f'Epoch {epoch}: train loss={loss.detach().item():.4f}. ' \\\n",
        "          f'Test accuracy {accuracy_score(df_test.target, preds.numpy() > 0.5):.4f} ' \\\n",
        "          f'ROC_AUC {roc_auc_score(df_test.target, preds.numpy()):.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c804d506-4224-4a11-9c01-d8d3a03d8e9a",
      "metadata": {},
      "source": [
        "Высокое качество классификации, является результатом успешного сочетания эффективной архитектуры LSTM и качественных эмбеддингов"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1539ce18-b550-43b6-9891-f8d9f0c10044",
      "metadata": {},
      "source": [
        "4.2. Проведите анализ ошибок – найдите новости, на которых модель ошибается, и предложите разумные объяснения этому."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "0470f702-1f52-4d78-9ed9-609c68e1b5a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def error_analysis():\n",
        "    model.eval()\n",
        "    ap = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            pred_logits = model(X)\n",
        "            preds = torch.sigmoid(pred_logits)\n",
        "            ap.append(preds)\n",
        "\n",
        "    ap = torch.cat(ap)\n",
        "\n",
        "    df_test['predicted'] = (ap.numpy() > 0.5).astype(int)\n",
        "    \n",
        "    errors = df_test[df_test['target'] != df_test['predicted']]\n",
        "    print (errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "ffe3bd04-4c02-4e98-8d33-ccaf0a7376a1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n",
            "640                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Семикратная победительница Уимблдона может на этой неделе отправиться в Антарктиду с тем, чтобы оттуда дать несколько прямых телеуроков игры в теннис. Соорудить подобие корта берется аргентинская антарктическая станция \"Вице-коммондор Марамбио\". Однако осуществить пожелание Штеффи Граф не так просто:станция находится в ведении аргентинского военного ведомства идоступ туда возможен только с разрешения правительства. Крометого, для полета на станцию необходим военно-транспортныйсамолет, способный совершить посадку на короткой снежнойполосе.   \n",
            "641                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Миланский хоккейный клуб \"Сайма\" получит на полмесяца нового технического советника в лице российского бомбардира из канадского клуба \"Оттава сенаторз\" Алексея Яшина. В соответствии с подписанным контрактом, 21 февраля Яшин прибудет в итальянскую экономическую столицу и в течение 15 дней будет помогать тренеру \"Саймы\" Ивано Дзанатта. По словам Яшина, он постарается передать миланской команде профессиональные секреты НХЛ и, возможно, даже сыграет несколько матчей за \"Сайму\". Приглашенный в 1993 году \"сенаторами\", Яшин дважды участвовал в \"Играх всех звезд\" НХЛ и в составе сборной России завоевал серебряную медаль на зимней Олимпиаде 1998 года.   \n",
            "644  В полуфинале Кубка Италии \"Венеция\" принимала римский \"Лацио\". Напомним, в первом матче римский \"Лацио\" на своем поле разгромил \"Венецию\" с неприличным счетом 5:0, чем досрочно обеспечил себе выход в финал Кубка. Так что ответная встреча превратилась в пустую формальность. На матч пришел посмотреть всего 381 зритель, что похоже на антирекорд кубковых матчей с участием клубов из серии А (высшего итальянского дивизиона). Матч закончился вничью - 2:2. Оба гола в составе римлян провел Симоне Индзаги. В первый раз он отличился уже на второй минуте матча. Вскоре после перерыва Фабиан Валтолина из \"Венеции\" метров с 20 восстановил равновесие. На 74-й минуте Симоне вновь вывел гостей вперед, замкнув головой навес Роберто Манчини. А на последней минуте игры бывший полузащитник норвежского \"Русенборга\" Рунар Берг, ныне выступающий за \"Венецию\", опять сделал счет ничейным (мяч после его удара коснулся защитника \"Лацио\" Паоло Негро и резко изменил направление полета). В добавленное арбитром время с поля было изгнано по одному игроку из каждой команды - новоиспеченный римлянин Фабрицио Раванелли (совсем недавно вернувшийся в Италию из Франции, где играл за марсельский \"Олимпик\") и защитник \"Венеции\" Франческо Педоне. В финале \"Лацио\" скорее всего встретится с миланским \"Интером\", который в своем полуфинале ведет после первого матча у \"Кальяри\" со счетом 3:1, а ответный матч проведет дома.   \n",
            "646                                                                                                                                                                                                                                        У главного тренера белорусской сборной по биатлону АлександраПопова похищена крупная сумма денег. В деньсвоего отъезда из Минска в норвежский Холменколлен, где 19февраля стартует чемпионат мира среди \"стреляющих лыжников\",Попов получил 40 тысяч долларов, которые предназначались напокрытие расходов сборной. По дороге домой он зашел в столичный ЦУМ, чтобы приобрести различные сувениры для зарубежных гостей. А уже в своей квартире, сняв наплечную сумку, где находились деньги, обнаружил, что они пропали. Александр сразу позвонил в свою федерацию, а сам отправился в милицию, где и занялись выясненим дела. Тем временем, благодаря энергичным действиям работниковфедерации и Министерства спорта и туризма, удалось собратьнеобходимую сумму долларов, с которой в Норвегию отправилсявице-президент Белорусской федерации биатлона Сергей Булыгин. Он и будет контролировать финансовое обеспечение белорусскойделегации на чемпионате мира. В настоящее время Александр Попов находится дома. Напомним,что 36-летний биатлонист был чемпионом Олимпиады-88 в Калгари в составе эстафетной команды, а также является многократнымчемпионом мира. По факту случившегося ведется следствие.   \n",
            "648                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Chicago Bulls расстались с последним игроком стартовой пятерки золотой команды девяностых - хорватским нападающим Тони Кукочем. Спортсмен отдан \"Филадельфии\", где составит ударную связку с лучшим снайпером Лиги Алленом Айверсоном. Взамен \"Филадельфия\" отправила в Chicago Bulls резервиста Брюса Боуэна. Еще один участник сделки, Golden State, получил из \"Филадельфии\"  Лэрри Хьюза и Билли Оуэнса, передав чикагцам ветерана Джона Старкса, который пропустил большую часть текущего чемпионата из-за травмы. Генеральный менеджер команды Джерри Краузе так прокомментировал трейд Кукоча: \"В Чикаго был только один неприкасаемый - Майкл Джордан. Все остальные у меня живут под страхом продажи. Таковы правила в НБА\". Между тем, по окончании этого сезона Кукоч станет свободным агентом и \"Филадельфии\" придется приложить немало усилий, чтобы обеспечить ему привлекательный контракт.   \n",
            "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ...   \n",
            "974                                               Несмотря на убедительную победу над \"Баварией\" в последнем матче второго этапа Лиги чемпионов (2:0) киевские динамовцы не попали в четвертьфинал.Их конкуренты - футболисты мадридского \"Реала\" смогли удержать минимальное преимущество во встрече с норвежским \"Русенборгом\" (1:0) и закрыть украинцам дорогу в четверку сильнейших команд Старого света. Исход киевского матча решили точные удары двух грузинских легионеров \"Динамо\": в первом тайме Каха Каладзе с одного метра забил мяч в ворота после розыгрыша углового, а во-втором Георгий Деметрадзе забил свой первый мяч за украинский клуб, нанеся прекрасный удар в падении через себя. \"Бавария\", уже обеспечившая себе первое место в группе, выставила на матч далеко не сильнейший состав: Кан, Эффенберг, Шолль, Янкер вообще не приехали в Киев. Играя против дублеров, украинцам не составило труда удержать победный счет. В это же время в Тронхейме \"Реал\" пытался обыграть \"Русенборг\". Мадридцы забили мяч уже на третьей минуте (отличился Рауль) и в первые четверть часа имели еще несколько голевых моментов. Однако, затем хозяева перехватили инициативу, и несколько раз только чудо спасало Королевский клуб. Тем не менее, испанцы удержали победу и опередили динамовцев в турнирной таблице за счет преимущества в личных встречах. В Мадриде сопернике сыграли вничью (2:2), а вот в Киеве победили гости (2:0).   \n",
            "981                                                                                                                                                                                                                                                                                                                                 Интереснейший национальный футбольный чемпионат - итальянский - мог растерять всех своих представителей в нынешнем цикле еврокубков. Последней надеждой Апеннин оставался \"Лацио\", играющий в Лиге чемпионов. Римляне проводили сложный матч в Лондоне с местным \"Челси\", и только победа гарантировала итальянцам место в четвертьфинале. И они добились ее  - 2:1. Правда, на 45-й минуте у поклонников \"Лацио\", наверняка, прихватило сердце: полузащитник \"Челси\" Пойет дальним ударом открыл счет, и команды сразу же ушли на перерыв. Но во втором тайме гости играли куда активнее хозяев, уже обеспечивших себе место в четвертьфинале. Индзаги и Михайлович забили по мячу, принеся своей команде не только победу, но и первое место в группе \"Д\". В другом матче этой четверки, в Марселе, \"Олимпик\" принимал \"Фейенорд\". У голландцев сохранялись неплохие шансы пробиться в четвертьфинал, однако особой активности гости не проявили, даже когда один из французских футболистов был удален с поля. Довольно скучная игра закончилась нулевой ничьей, и оба соперника завершили выступления в еврокубках.   \n",
            "987                                                                   Два английских клуба - \"Арсенал\" и \"Лидс\", а также турецкий \"Галатасарай\" и французский \"Ланс\" стали полуфиналистами Кубка УЕФА. Это произошло в результате повторных четверьфинальных матчей второго по престижности европейского клубного футбольного турнира. Испанская \"Сельта\", в составе которой выступают россияне Валерий Карпин и Александр Мостовой, по сумме двух встреч уступила дорогу в полуфинал французскому \"Лансу\". Первый матч в Виго завершился неделю назад вничью (0:0). Ни одного мяча не забили соперники и в первом тайме игры в Лансе. Зато в начале второго тайма нападающий \"Сельты\" Ревиво забил гол, поставив хозяев в непростое положение: теперь для выхода в полуфинал им надо было заработать два очка. И хозяева справились с этой задачей, забив по мячу на 63-й и 73-й минутах и победив со счетом 2:1. В остальных четвертьфинальных парах интрига исчезла уже после первых матчей. Турецкий \"Галатасарай\", разгромив в первом матче в гостях \"Мальорку\" (4:1), оказался сильнее и в домашнем поединке (2:1). Чешская \"Славия\", хотя и выиграла у английского \"Лидса\" на своем поле (2:1), неделей ранее уступила на выезде (0:3) и выбыла из борьбы. Наконец, лондонский \"Арсенал\", выиграв в первой встрече дома у бременского \"Вердера\" (2:0), закрепил победу в гостевой встрече (4:2). Три мяча у англичан забил полузащитник Рей Парлоур.   \n",
            "988                                                                                                                                                                                                                                                                                                                                                                                                              В пятницу 24 марта на московском стадионе \"Локомотив\" матчем железнодорожников и их земляков армейцев стартует 9 чемпионат России по футболу. Продлится национальное первенство семь с половиной месяцев. 16 команд заявили для участия в чемпионате 571 футболиста, из которых 464 - россияне. По сравнению с прошлым сезоном легионеров в высшем дивизионе стало меньше: 107 против 114 в 1999-м году. 30 игроков представляют Украину, 17 - Белоруссию, 10 - Литву. Заявили клубы и футболистов и из дальнего зарубежья: Бразилии (6), Югославии (3), Нигерии, Камеруна, Словении, Македонии, Словакии, Боснии (по одному). Больше всего иностранцев - 14 - заявила владикавказская \"Алания\". Не до конца решен вопрос о трансляции матчей чемпионата по телевидению. Как сообщил президент Профессиональной Футбольной Лиги Николай Толстых,  ведутся переговоры с руководителями центральных телеканалов. Решение по этому вопросу будет принято в конце марта. Первый же матч чемпионата будет показан в записи на телеканале \"НТВ\".   \n",
            "992                                                                                                                                                                                                                                                                                                     Состоявшаяся в штаб-квартире УЕФА в швейцарском Нионе жеребьевка четвертьфинала Лиги чемпионов развела три испанские команды по разным парам. Таким образом, впервые в истории престижнейшего европейского футбольного турнира сразу три представителя одной страны могут попасть в полуфинал. Один из главных фаворитов Лиги - \"Барселона\" - сыграет в четвертьфинале с английским \"Челси\". Первый матч состоится в Лондоне. Другие пары четвертьфиналистов составили \"Валенсия\" (Испания) - \"Лацио\" (Италия), \"Реал\" (Испания) - \"Манчестер Юнайтед\" (Англия), \"Порто\" (Португалия) - \"Бавария\" (Германия). Первые матчи пройдут 4 и 5 апреля на полях команд, указанных первыми. Ответные игры состоятся через две недели. В полуфиналах встретятся победители двух первых и двух последних из перечисленных пар. А в полуфинале Кубка УЕФА 6 и 20 апреля турецкий \"Галатасарай\" померится силами с английским \"Лидсом\", а другой клуб с Туманного Альбиона \"Арсенал\" поспорит за выход в финал с французским \"Лансом\". Представители \"Лидса\" уже выразили удовлетворение тем, что в полуфинале им не придется соперничать с соотечественниками.   \n",
            "\n",
            "     target  predicted  \n",
            "640       0          1  \n",
            "641       0          1  \n",
            "644       0          1  \n",
            "646       0          1  \n",
            "648       0          1  \n",
            "..      ...        ...  \n",
            "974       0          1  \n",
            "981       0          1  \n",
            "987       0          1  \n",
            "988       0          1  \n",
            "992       0          1  \n",
            "\n",
            "[74 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "error_analysis()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3aacc72b-d618-42ee-afed-ff09a24b5f5c",
      "metadata": {},
      "source": [
        "Объяснение ошибок:\n",
        "Текст может имееть разные смыслы, т.е. неоднозначен ну и из-за ключивых слов, которые могут быть паралельны"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aab1fa71-e5ce-46fc-b39c-e86598800237",
      "metadata": {},
      "source": [
        "4.3. Усовершенствуйте классификатор, чтобы он осуществлял многоклассовую \n",
        "классификацию (классы «Культура», «Спорт», «Экономика»)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "5eb971c5-d17f-4598-8ccb-bd8c8c0de5e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "class_mapping = {\"Культура\": 0, \"Спорт\": 1, \"Экономика\": 2}\n",
        "df[\"target\"] = df[\"topic\"].map(class_mapping)\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "df = df.sample(frac=1.).reset_index(drop=True)\n",
        "df_test = df[:1000].copy()\n",
        "df_train = df[1000:].copy().reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a39ea132-e56b-4f1f-85af-b690a9577b9d",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = torch.stack([text_to_ids(emb, x, 50) for x in df.text], 0)\n",
        "y = torch.tensor(df.target, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e40e8bea-a9c3-461b-9c31-8c9c1317afd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test = torch.stack([text_to_ids(emb, x, 50) for x in df_test.text], 0)\n",
        "y_test = torch.unsqueeze(torch.tensor(df_test.target, dtype=torch.long), 1)\n",
        "data_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X, y), batch_size=8)\n",
        "test_data_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(X_test, y_test), batch_size=16, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "78eac5ec-3456-43fc-9a94-2099657f8b2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ImprovedLSTMClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.embedding = NavecEmbedding(emb)\n",
        "        self.lstm = nn.LSTM(300, 30, batch_first=True)\n",
        "        self.fc = nn.Linear(30, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x, _ = self.lstm(x)\n",
        "        x = x[:, -1, :]\n",
        "        x = self.fc(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7890ce2d-044e-484e-88cb-778907440292",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "model = ImprLSTMClassifier(num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "f3987ac0-3ca3-45bb-918c-b73bf39d85df",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: train loss=0.0273. Test accuracy 0.9870 ROC_AUC 0.9992\n",
            "Epoch 1: train loss=0.0114. Test accuracy 0.9910 ROC_AUC 0.9996\n",
            "Epoch 2: train loss=0.0197. Test accuracy 0.9940 ROC_AUC 0.9998\n",
            "Epoch 3: train loss=0.1614. Test accuracy 0.9910 ROC_AUC 0.9999\n",
            "Epoch 4: train loss=0.2540. Test accuracy 0.9950 ROC_AUC 1.0000\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    for X, y in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred_logits = model(X)\n",
        "        loss = criterion(pred_logits, y.squeeze())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    model.eval()\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            pred_logits = model(X)\n",
        "            preds.append(pred_logits)\n",
        "    preds = torch.cat(preds)\n",
        "    \n",
        "    preds_classes = preds.argmax(dim=1)\n",
        "    \n",
        "    roc_auc = roc_auc_score(df_test.target, F.softmax(preds, dim=1).numpy(), multi_class='ovr')\n",
        "    print(f'Epoch {epoch}: train loss={loss.detach().item():.4f}. ' \\\n",
        "        f'Test accuracy {accuracy_score(df_test.target, preds_classes):.4f} ' \\\n",
        "        f'ROC_AUC {roc_auc:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b1bee6ba-8f00-4317-8a40-426b1742a8c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def errors1_analysis():\n",
        "    model.eval()\n",
        "    ap = []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_data_loader:\n",
        "            pred_logits = model(X)\n",
        "            preds = F.softmax(pred_logits, dim=1)\n",
        "            ap.append(preds)\n",
        "\n",
        "    ap = torch.cat(ap)\n",
        "\n",
        "    df_test['predicted'] = ap.argmax(dim=1).numpy()\n",
        "    \n",
        "    errors= df_test[df_test['target'] != df_test['predicted']]\n",
        "    print (errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "605941ac-a57a-4926-ad3f-ff5472831782",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                 url  \\\n",
            "426         https://lenta.ru/news/2013/02/25/circus/   \n",
            "473     https://lenta.ru/news/2013/03/13/winemaking/   \n",
            "607   https://lenta.ru/news/2001/05/28/papa_ukraina/   \n",
            "620        https://lenta.ru/news/2004/01/13/tarasov/   \n",
            "765  https://lenta.ru/news/2010/04/06/annileibovitz/   \n",
            "\n",
            "                                                 title  \\\n",
            "426       Цирку Никулина утвердили аренду в один рубль   \n",
            "473                     Никита Михалков стал виноделом   \n",
            "607  Папа Римский проведет в Киеве и Львове правосл...   \n",
            "620  Бизнесмен Артем Тарасов собирает деньги на диа...   \n",
            "765     От Анни Лейбовиц потребовали миллион через суд   \n",
            "\n",
            "                                                  text      topic    tags  \\\n",
            "426  Арендную плату в один рубль за квадратный метр...   Культура   Театр   \n",
            "473  Актер и режиссер Никита Михалков вместе с парт...  Экономика  Деньги   \n",
            "607  Папский нунций (посол) в Киеве Николай Этерови...   Культура     Все   \n",
            "620  Бизнесмен Артем Тарасов привез в Россию диадем...   Культура     Все   \n",
            "765  Инвестиционная компания Brunswick Capital Part...   Культура     Все   \n",
            "\n",
            "           date  target  predicted  \n",
            "426  2013/02/25       0          2  \n",
            "473  2013/03/13       2          0  \n",
            "607  2001/05/28       0          2  \n",
            "620  2004/01/13       0          2  \n",
            "765  2010/04/06       0          2  \n"
          ]
        }
      ],
      "source": [
        "errors1_analysis()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
